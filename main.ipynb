{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-28 16:57:40.478146: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-28 16:57:40.496307: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-28 16:57:40.615756: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-28 16:57:40.617092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 16:57:41.584655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "66/66 [==============================] - 227s 3s/step - loss: 1.3102 - accuracy: 0.4749\n",
      "Epoch 2/6\n",
      "66/66 [==============================] - 221s 3s/step - loss: 1.1032 - accuracy: 0.5128\n",
      "Epoch 3/6\n",
      "66/66 [==============================] - 229s 3s/step - loss: 0.9079 - accuracy: 0.6209\n",
      "Epoch 4/6\n",
      "66/66 [==============================] - 217s 3s/step - loss: 0.7431 - accuracy: 0.7261\n",
      "Epoch 5/6\n",
      "66/66 [==============================] - 215s 3s/step - loss: 0.6094 - accuracy: 0.8038\n",
      "Epoch 6/6\n",
      "66/66 [==============================] - 227s 3s/step - loss: 0.4731 - accuracy: 0.8531\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your dataset (replace 'reviews.csv' with your dataset path)\n",
    "# The dataset should have columns: 'Place', 'Review', and 'Sentiment'\n",
    "df = pd.read_csv('reviews.csv', sep=',')\n",
    "def preprocess_text(text):\n",
    "    # Add your text preprocessing steps here\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['A Detailed Review of the Place'] = df['A Detailed Review of the Place'].apply(preprocess_text)\n",
    "\n",
    "# Map ratings to sentiment labels\n",
    "def map_rating_to_sentiment(rating):\n",
    "    return rating\n",
    "\n",
    "df['sentiment'] = df['On a Scale of 1-5 Rate the Place'].apply(map_rating_to_sentiment)\n",
    "\n",
    "# Map sentiment labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Initialize DistilBERT tokenizer\n",
    "max_seq_length = 128\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', max_length=max_seq_length, truncation=True, padding='max_length')\n",
    "\n",
    "# Tokenize and encode the data\n",
    "x_encoded = tokenizer(list(df['A Detailed Review of the Place']), return_tensors='tf', padding=True, truncation=True, max_length=max_seq_length)\n",
    "y_encoded = df['Sentiment']\n",
    "\n",
    "# Initialize DistilBERT model\n",
    "num_labels = len(df['Sentiment'].unique())\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compile the model with adjusted hyperparameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Increase the number of epochs for better training\n",
    "epochs = 6  # Increase the number of epochs for better results\n",
    "\n",
    "# Model training on the entire dataset\n",
    "history = model.fit(\n",
    "    x={'input_ids': x_encoded['input_ids'], 'attention_mask': x_encoded['attention_mask']},\n",
    "    y=y_encoded,\n",
    "    epochs=epochs,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Function to predict sentiment for a review\n",
    "def predict_sentiment(review):\n",
    "    # Tokenize and encode the review\n",
    "    review_encoded = tokenizer([preprocess_text(review)], return_tensors='tf', padding=True, truncation=True, max_length=max_seq_length)\n",
    "\n",
    "    # Predict sentiment\n",
    "    sentiment = model.predict({'input_ids': review_encoded['input_ids'], 'attention_mask': review_encoded['attention_mask']})[0]\n",
    "    sentiment_label = label_encoder.inverse_transform([np.argmax(sentiment)])[0]\n",
    "\n",
    "    return sentiment_label\n",
    "\n",
    "# Example usage of the predict_sentiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a directory\n",
    "model.save_pretrained('distilbert_model_new')\n",
    "\n",
    "# Save the tokenizer to the same directory\n",
    "tokenizer.save_pretrained('distilbert_model_new')\n",
    "\n",
    "# Save the label encoder using joblib\n",
    "import joblib\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rating_to_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return \"Bored\"\n",
    "    elif rating == 3:\n",
    "        return \"Mixed\"\n",
    "    elif rating >= 4:\n",
    "        return \"Happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 848ms/step\n",
      "Predicted sentiment for the review: 1.0\n"
     ]
    }
   ],
   "source": [
    "user_review = \"This place sucks. I hated it.\"\n",
    "predicted_sentiment = predict_sentiment(user_review)\n",
    "print(f\"Predicted sentiment for the review: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 996ms/step\n",
      "Predicted sentiment for the review: 3.0\n"
     ]
    }
   ],
   "source": [
    "user_review = \"Good historical place to visit but too crowded. The place needs to be be maintained by the authorities for cleanliness as the locals, hawkers, shops and the tourists litter the place with disposals. People over there should be advised and fines to be imposed on breaking the rules. It is a pity that such a beautiful historic place is not maintained. One should not forget to have the falooda and lassi nearby. Shopping for glass bangles is a must for the ladies.\"\n",
    "predicted_sentiment = predict_sentiment(user_review)\n",
    "print(f\"Predicted sentiment for the review: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicted sentiment for the review: 5.0\n"
     ]
    }
   ],
   "source": [
    "user_review = \"Noob bullshit \"\n",
    "predicted_sentiment = predict_sentiment(user_review)\n",
    "print(f\"Predicted sentiment for the review: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted sentiment for the review: 2.0\n"
     ]
    }
   ],
   "source": [
    "user_review = \"I will not go again.Worst place\"\n",
    "predicted_sentiment = predict_sentiment(user_review)\n",
    "print(f\"Predicted sentiment for the review: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted sentiment for the review: 5.0\n"
     ]
    }
   ],
   "source": [
    "user_review = \"Must visit\"\n",
    "predicted_sentiment = predict_sentiment(user_review)\n",
    "print(f\"Predicted sentiment for the review: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "Predicted sentiment for the review: 4.0\n"
     ]
    }
   ],
   "source": [
    "user_review = \"it was okay place. I would recommend it to anyone.\"\n",
    "predicted_sentiment = predict_sentiment(user_review)\n",
    "print(f\"Predicted sentiment for the review: {predicted_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating={}\n",
    "likely_partner={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_sentiments = ['Charminar', 'Golconda Fort', 'Wonderla', 'Ramoji Film City', 'Nehru Zoological Park', 'Birla Science Museum', 'Hussain Sagar Lake', 'Birla mandir', 'Cable Bridge', 'NTR Garden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_process(place):\n",
    "    place_temp = df[df['Place You Want to Review About'] == place]\n",
    "    partner_counts=place_temp['Who Was Your Company During Your Visit'].value_counts()\n",
    "    max_partner = partner_counts.idxmax()\n",
    "    likely_partner[place]=max_partner\n",
    "    \n",
    "    \n",
    "    sum_ratings = place_temp['On a Scale of 1-5 Rate the Place'].sum()\n",
    "    num_entries = place_temp.shape[0]\n",
    "    average_rating = sum_ratings / num_entries\n",
    "    avg_rating[place]=average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Charminar': 4.0181818181818185,\n",
       " 'Golconda Fort': 4.554545454545455,\n",
       " 'Wonderla': 4.733333333333333,\n",
       " 'Ramoji Film City': 4.181818181818182,\n",
       " 'Nehru Zoological Park': 4.166666666666667,\n",
       " 'Birla Science Museum': 4.291139240506329,\n",
       " 'Hussain Sagar Lake': 4.033333333333333,\n",
       " 'Birla mandir': 4.6,\n",
       " 'Cable Bridge': 3.108695652173913,\n",
       " 'NTR Garden': 3.725}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for place in place_sentiments:\n",
    "    place_process(place)\n",
    "avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Charminar': 'Family',\n",
       " 'Golconda Fort': 'Couples',\n",
       " 'Wonderla': 'Friends',\n",
       " 'Ramoji Film City': 'Family',\n",
       " 'Nehru Zoological Park': 'Family',\n",
       " 'Birla Science Museum': 'Family',\n",
       " 'Hussain Sagar Lake': 'Family',\n",
       " 'Birla mandir': 'Family',\n",
       " 'Cable Bridge': 'Friends',\n",
       " 'NTR Garden': 'Family'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for place in place_sentiments:\n",
    "    place_process(place)\n",
    "likely_partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
